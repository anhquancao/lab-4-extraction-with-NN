{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "## Question 0 - Get common wikidata occupations\n",
    "\n",
    "> Write a sparql query that retrieves the top 100 occupations on wikidata (wikidata property P106).\n",
    "\n",
    "You may use the interface https://query.wikidata.org/ to try different queries. Here are some example sparql queries: https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/queries/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ?o (COUNT(?person) AS ?count) WHERE \n",
    "{\n",
    "   ?person wdt:P106 ?o\n",
    "}\n",
    "GROUP BY ?o\n",
    "ORDER BY DESC(?count)\n",
    "LIMIT 100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assertion should pass if your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "occupations = ['Q82955', 'Q937857', 'Q36180', 'Q33999', 'Q1650915', 'Q1028181', 'Q1930187', 'Q177220', 'Q1622272', 'Q49757', 'Q36834', 'Q40348', 'Q47064', 'Q639669', 'Q10800557', 'Q201788', 'Q2526255', 'Q43845', 'Q28389', 'Q42973', 'Q10871364', 'Q39631', 'Q193391', 'Q482980', 'Q483501', 'Q11513337', 'Q3665646', 'Q12299841', 'Q19204627', 'Q16533', 'Q81096', 'Q11774891', 'Q188094', 'Q1281618', 'Q333634', 'Q189290', 'Q250867', 'Q33231', 'Q2259451', 'Q42603', 'Q628099', 'Q37226', 'Q2309784', 'Q901', 'Q2066131', 'Q6625963', 'Q10798782', 'Q2374149', 'Q170790', 'Q4610556', 'Q185351', 'Q486748', 'Q3055126', 'Q753110', 'Q4964182', 'Q169470', 'Q158852', 'Q1234713', 'Q14089670', 'Q10873124', 'Q3282637', 'Q593644', 'Q947873', 'Q13414980', 'Q131524', 'Q11338576', 'Q15117302', 'Q488205', 'Q14467526', 'Q183945', 'Q10843402', 'Q13382576', 'Q13141064', 'Q214917', 'Q855091', 'Q644687', 'Q19595175', 'Q121594', 'Q2865819', 'Q16010345', 'Q1231865', 'Q2405480', 'Q350979', 'Q3400985', 'Q13365117', 'Q10833314', 'Q3621491', 'Q15981151', 'Q212980', 'Q16145150', 'Q1792450', 'Q15296811', 'Q15627169', 'Q2306091', 'Q4263842', 'Q806798', 'Q5716684', 'Q2516866', 'Q3387717', 'Q131512']\n",
    "\n",
    "def evalSparql(query):\n",
    "    return requests.post('https://query.wikidata.org/sparql', data=query, headers={\n",
    "        'content-type': 'application/sparql-query',\n",
    "        'accept': 'application/json',\n",
    "        'user-agent': 'User:Tpt'\n",
    "    }).json()['results']['bindings']\n",
    "\n",
    "myOccupations = [val['o']['value'].replace('http://www.wikidata.org/entity/', '') \n",
    "                 for val in evalSparql(query)]\n",
    "assert(frozenset(occupations) == frozenset(myOccupations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupations labels\n",
    "\n",
    "We load the labels of the occupations from Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q121594': 'professor', 'Q82955': 'politician', 'Q81096': 'engineer', 'Q177220': 'singer', 'Q169470': 'physicist', 'Q201788': 'historian', 'Q170790': 'mathematician', 'Q158852': 'conductor', 'Q214917': 'playwright', 'Q188094': 'economist', 'Q212980': 'psychologist', 'Q131524': 'entrepreneur', 'Q482980': 'author', 'Q193391': 'diplomat', 'Q185351': 'jurist', 'Q250867': 'Catholic priest', 'Q483501': 'artist', 'Q488205': 'singer-songwriter', 'Q593644': 'chemist', 'Q639669': 'musician', 'Q350979': 'zoologist', 'Q486748': 'pianist', 'Q333634': 'translator', 'Q937857': 'association football player', 'Q806798': 'banker', 'Q1028181': 'painter', 'Q183945': 'record producer', 'Q855091': 'guitarist', 'Q644687': 'illustrator', 'Q1234713': 'theologian', 'Q947873': 'television presenter', 'Q1281618': 'sculptor', 'Q753110': 'songwriter', 'Q1792450': 'art historian', 'Q1930187': 'journalist', 'Q1650915': 'researcher', 'Q2066131': 'athlete', 'Q2374149': 'botanist', 'Q2526255': 'film director', 'Q2516866': 'publisher', 'Q2405480': 'voice actor', 'Q2306091': 'sociologist', 'Q2865819': 'opera singer', 'Q1231865': 'pedagogue', 'Q3282637': 'film producer', 'Q1622272': 'university teacher', 'Q3400985': 'academic', 'Q3665646': 'basketball player', 'Q3055126': 'entomologist', 'Q3387717': 'theatre director', 'Q3621491': 'archaeologist', 'Q189290': 'military officer', 'Q4263842': 'literary critic', 'Q4610556': 'model', 'Q4964182': 'philosopher', 'Q5716684': 'dancer', 'Q6625963': 'novelist', 'Q2259451': 'stage actor', 'Q628099': 'association football manager', 'Q10833314': 'tennis player', 'Q10843402': 'swimmer', 'Q10800557': 'film actor', 'Q10871364': 'baseball player', 'Q10873124': 'chess player', 'Q11338576': 'boxer', 'Q10798782': 'television actor', 'Q11774891': 'ice hockey player', 'Q11513337': 'athletics competitor', 'Q12299841': 'cricketer', 'Q13141064': 'badminton player', 'Q13365117': 'handball player', 'Q13414980': 'Australian rules footballer', 'Q14089670': 'rugby union player', 'Q14467526': 'linguist', 'Q131512': 'agriculturer', 'Q15117302': 'volleyball player', 'Q15981151': 'jazz musician', 'Q16010345': 'performer', 'Q2309784': 'sport cyclist', 'Q19204627': 'American football player', 'Q15296811': 'drawer', 'Q15627169': 'trade unionist', 'Q19595175': 'amateur wrestler', 'Q13382576': 'rower', 'Q16145150': 'music pedagogue', 'Q28389': 'screenwriter', 'Q33231': 'photographer', 'Q36180': 'writer', 'Q43845': 'businessperson', 'Q33999': 'actor', 'Q36834': 'composer', 'Q901': 'scientist', 'Q42973': 'architect', 'Q49757': 'poet', 'Q42603': 'priest', 'Q39631': 'physician', 'Q40348': 'lawyer', 'Q37226': 'teacher', 'Q16533': 'judge', 'Q47064': 'military personnel'}\n"
     ]
    }
   ],
   "source": [
    "occupations_label = {}\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT ?o ?oLabel \n",
    "WHERE { \n",
    "    VALUES ?o { %s } \n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"% ' '.join('wd:' + o for o in occupations)\n",
    "\n",
    "for result in evalSparql(query):\n",
    "    occupations_label[result['o']['value'].replace('http://www.wikidata.org/entity/', '')] = result['oLabel']['value']\n",
    "\n",
    "print(occupations_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load *all* the labels of the occupations from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q121594': ['professor', 'Prof.'], 'Q82955': ['politician', 'political leader', 'polit.', 'political figure'], 'Q81096': ['engineer'], 'Q177220': ['singer', 'vocalist'], 'Q169470': ['physicist'], 'Q201788': ['historian', 'historians', 'historiographer'], 'Q170790': ['mathematician'], 'Q158852': ['conductor', 'Conducting'], 'Q214917': ['playwright', 'Playwright, dramatist', 'dramatist', 'scriptwriter', 'playwrite'], 'Q188094': ['economist'], 'Q212980': ['psychologist'], 'Q131524': ['entrepreneur'], 'Q482980': ['author'], 'Q193391': ['diplomat'], 'Q185351': ['jurist'], 'Q250867': ['Catholic priest', 'Roman Catholic priest', 'Catholic presbyter', 'Roman Catholic presbyter'], 'Q483501': ['artist'], 'Q488205': ['singer-songwriter', 'singer/songwriter', 'singer songwriter', 'singersongwriter'], 'Q593644': ['chemist', 'chemists'], 'Q639669': ['musician'], 'Q350979': ['zoologist', 'zooligist'], 'Q486748': ['pianist'], 'Q333634': ['translator'], 'Q937857': ['association football player', 'footballer', 'football player', 'association footballer', 'soccer player'], 'Q806798': ['banker', 'Private Banker', 'private sector banker'], 'Q1028181': ['painter'], 'Q183945': ['record producer', 'music producer'], 'Q855091': ['guitarist', 'guitar player'], 'Q644687': ['illustrator'], 'Q1234713': ['theologian', 'religious scholar'], 'Q947873': ['television presenter', 'TV presenter', 'hostess', 'TV host', 'TV personality', 'host', 'television personality', 'television host'], 'Q1281618': ['sculptor'], 'Q753110': ['songwriter', 'song writer'], 'Q1792450': ['art historian'], 'Q1930187': ['journalist', 'journo'], 'Q1650915': ['researcher'], 'Q2066131': ['athlete', 'sportsperson', 'sportsman', 'sportswoman'], 'Q2374149': ['botanist', 'botany', 'plant scientist'], 'Q2526255': ['film director', 'director', 'movie director'], 'Q2516866': ['publisher'], 'Q2405480': ['voice actor', 'voice actress', 'voice artist'], 'Q2306091': ['sociologist'], 'Q2865819': ['opera singer'], 'Q1231865': ['pedagogue', 'educationalist'], 'Q3282637': ['film producer', 'producer', 'movie producer'], 'Q1622272': ['university teacher', 'lecturer', 'university teachers', 'college lecturer', 'college professor'], 'Q3400985': ['academic', 'college graduates', 'university graduates'], 'Q3665646': ['basketball player', 'professional basketball player', 'basketballer'], 'Q3055126': ['entomologist'], 'Q3387717': ['theatre director', 'theater director', 'stage director'], 'Q3621491': ['archaeologist', 'archeologist'], 'Q189290': ['military officer', 'army officer', 'officer'], 'Q4263842': ['literary critic', 'book critic', 'literary critique'], 'Q4610556': ['model', 'fashion model', 'mannequin'], 'Q4964182': ['philosopher'], 'Q5716684': ['dancer'], 'Q6625963': ['novelist'], 'Q2259451': ['stage actor', 'stage actress', 'theater actor', 'theater actress', 'theatre actor', 'theatre actress'], 'Q628099': ['association football manager', 'football manager', 'association football coach', 'football coach', 'soccer coach', 'soccer manager'], 'Q10833314': ['tennis player'], 'Q10843402': ['swimmer'], 'Q10800557': ['film actor', 'film actress', 'movie actor', 'movie actress'], 'Q10871364': ['baseball player'], 'Q10873124': ['chess player'], 'Q11338576': ['boxer', 'pugilist'], 'Q10798782': ['television actor', 'actor', 'actress', 'television actress', 'TV actor', 'TV actress'], 'Q11774891': ['ice hockey player', 'hockey player'], 'Q11513337': ['athletics competitor', 'track and field athlete', 'athlete (restricted sense)'], 'Q12299841': ['cricketer', 'cricket player'], 'Q13141064': ['badminton player'], 'Q13365117': ['handball player', 'handballer'], 'Q13414980': ['Australian rules footballer', 'Australian footballer', 'Australian rules football player', 'Australian-rules football player'], 'Q14089670': ['rugby union player'], 'Q14467526': ['linguist', 'linguistic scholar'], 'Q131512': ['agriculturer', 'farmer', 'agriculturist', 'cultivator', 'grower', 'raiser'], 'Q15117302': ['volleyball player', 'volleyballer'], 'Q15981151': ['jazz musician'], 'Q16010345': ['performer', 'performing artist', 'scenic artist'], 'Q2309784': ['sport cyclist', 'racing cyclist', 'sport bicyclist', 'sport biker'], 'Q19204627': ['American football player', 'football player'], 'Q15296811': ['drawer', 'illustrator', 'draughtsperson', 'draughtsman', 'draftsperson', 'draftsman', 'draftswoman', 'drafter'], 'Q15627169': ['trade unionist', 'labor unionist', 'labour unionist'], 'Q19595175': ['amateur wrestler', 'wrestler'], 'Q13382576': ['rower', 'oarsman', 'oarswoman'], 'Q16145150': ['music pedagogue', 'music teacher'], 'Q28389': ['screenwriter', 'writer', 'screen writer', 'scriptwriter', 'scenarist', 'film writer', 'tv writer', 'script writer'], 'Q33231': ['photographer'], 'Q36180': ['writer', 'author', 'writers', 'authors'], 'Q43845': ['businessperson', 'businessman', 'dealer', 'business person', 'business woman', 'businesswoman', 'business man'], 'Q33999': ['actor', 'actors', 'actresses', 'actress'], 'Q36834': ['composer'], 'Q901': ['scientist', 'natural philosopher'], 'Q42973': ['architect'], 'Q49757': ['poet', 'bard', 'poetess'], 'Q42603': ['priest', 'priestess', 'reverend'], 'Q39631': ['physician', 'physicians'], 'Q40348': ['lawyer', 'attorney', 'Jurisprudente'], 'Q37226': ['teacher', 'professor', 'educator', 'schoolmaster', 'schoolmistress', 'school teacher'], 'Q16533': ['judge', 'magistrate', 'justice', 'judges', 'justices'], 'Q47064': ['military personnel']}\n"
     ]
    }
   ],
   "source": [
    "occupations_labels = {k: [v] for k, v in occupations_label.items()}\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?o ?altLabel \n",
    "WHERE {\n",
    "  VALUES ?o { %s }\n",
    "  ?o skos:altLabel ?altLabel . FILTER (lang(?altLabel) = \"en\")\n",
    "}\"\"\" % ' '.join('wd:' + o for o in occupations) \n",
    "\n",
    "for result in evalSparql(query):\n",
    "    occupations_labels[result['o']['value'].replace('http://www.wikidata.org/entity/', '')].append(result['altLabel']['value'])\n",
    "\n",
    "print(occupations_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia articles\n",
    "\n",
    "Here we load the training and the testing sets. To save memory space we use a generator that will read the file each time we iterate over the training or the testing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def loadJson(filename):\n",
    "    with gzip.open(filename, 'rt') as fp:\n",
    "        for line in fp:\n",
    "            yield json.loads(line)\n",
    "\n",
    "class MakeIter(object):\n",
    "    def __init__(self, generator_func, **kwargs):\n",
    "        self.generator_func = generator_func\n",
    "        self.kwargs = kwargs\n",
    "    def __iter__(self):\n",
    "        return self.generator_func(**self.kwargs)\n",
    "\n",
    "training_set = MakeIter(loadJson, filename='wiki-train.json.gz')\n",
    "testing_set = MakeIter(loadJson, filename='wiki-test.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract occupations from summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Dictionnary extraction\n",
    "\n",
    "> Using ```occupations_labels``` dictionnary, identify all occupations for each articles. Complete the function below to evaluate the accuracy of such approach. It will serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4842586814146957"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_occ = dict()\n",
    "for key, occs in occupations_labels.items():\n",
    "    for occ in occs:\n",
    "        label_to_occ[occ.lower()] = key\n",
    "\n",
    "def predict_dictionnary(example, occupations_labels):\n",
    "    occs = []\n",
    "    summary = example['summary'].lower()\n",
    "    labels = label_to_occ.keys()\n",
    "    for label in labels:\n",
    "        if label in summary:\n",
    "            occs.append(label_to_occ[label])\n",
    "    return occs\n",
    "    \n",
    "def evaluate_dictionnary(training_set, occupations_labels):\n",
    "    nexample = 0\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for example in training_set:\n",
    "        prediction = predict_dictionnary(example, occupations_labels)\n",
    "        p = frozenset(prediction)\n",
    "        g = frozenset(example['occupations'])\n",
    "        accuracy += 1.*len(p & g) / len(p | g)\n",
    "        nexample += 1\n",
    "    return accuracy / nexample\n",
    "\n",
    "evaluate_dictionnary(training_set, occupations_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the articles \"summary\" and we take the average of the word vectors.\n",
    "This is done with spacy loaded with the fast text vectors.\n",
    "To do the installation/loading [takes 8-10 minutes, dl 1.2Go]\n",
    "```\n",
    "pip3 install spacy\n",
    "wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/cc.en.300.vec.gz\n",
    "python3 -m spacy init-model en /tmp/en_vectors_wiki_lg --vectors-loc cc.en.300.vec.gz\n",
    "rm cc.en.300.vec.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nlp = spacy.load('/tmp/en_vectors_wiki_lg')\n",
    "\n",
    "def vectorize(dataset, nlp):\n",
    "    result = {}\n",
    "    for example in dataset:\n",
    "        doc = nlp(example['summary'], disable=['parser', 'tagger'])\n",
    "        result[example['title']] = {}\n",
    "        result[example['title']]['vector'] = doc.vector\n",
    "        result[example['title']]['summary'] = example['summary']\n",
    "        if 'occupations' in example:\n",
    "            result[example['title']]['occupations'] = example['occupations']\n",
    "    return result\n",
    "    \n",
    "vectorized_training = vectorize(training_set, nlp)\n",
    "vectorized_testing = vectorize(testing_set, nlp)\n",
    "nlp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427798"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.45162819e-02 -2.45802402e-02 -4.59302496e-03 -4.09372151e-02\n",
      " -4.47662771e-02 -4.18604538e-03 -3.15232435e-03 -1.44802360e-02\n",
      " -1.68499984e-02 -3.69651243e-03 -1.16255814e-02  1.43651171e-02\n",
      "  2.02674349e-03 -5.88953542e-03 -2.17011590e-02  1.02302311e-02\n",
      " -2.49313917e-02 -5.65232616e-03 -2.25581434e-02  8.29069968e-03\n",
      " -1.44069805e-03  2.25197673e-02 -6.81395701e-04 -1.37232570e-02\n",
      " -1.26674427e-02 -3.35569866e-02  1.10627888e-02 -2.37208814e-03\n",
      " -2.30000000e-02  7.58616179e-02 -5.03487710e-04 -2.51116175e-02\n",
      "  9.26511642e-03 -2.52558179e-02 -1.51058156e-02 -9.51627828e-03\n",
      "  1.17523270e-02  1.22441910e-03  1.08139520e-03  3.39302444e-03\n",
      "  2.20116391e-03  1.46860480e-02 -1.43686021e-02  5.76395402e-03\n",
      "  1.74162779e-02 -4.76220921e-02 -1.72569733e-02 -1.49988411e-02\n",
      " -1.77732538e-02  1.58907007e-02 -7.23255938e-03  2.43825577e-02\n",
      " -2.73104683e-02 -3.67430188e-02 -1.48802334e-02 -1.34825567e-02\n",
      " -3.14348824e-02  1.95930228e-02 -6.68605033e-04 -9.24302172e-03\n",
      "  1.56976283e-04 -1.65674444e-02 -1.30372085e-02  6.16298130e-05\n",
      " -3.63139645e-03  2.74534873e-03 -1.62697677e-02 -4.70697694e-03\n",
      "  5.48139494e-03  4.39302297e-03  4.65523303e-02  2.29872130e-02\n",
      "  2.72058025e-02 -5.52790612e-03  2.19720937e-02 -4.41581383e-02\n",
      "  1.33255811e-03  1.20244222e-02  3.49267460e-02  3.76593024e-02\n",
      "  8.65232572e-03 -6.52325572e-03 -1.90407019e-02  1.03569757e-02\n",
      "  1.09301973e-03 -6.28488278e-03  3.98965068e-02 -3.81744131e-02\n",
      " -1.35965087e-02  1.74023230e-02 -1.48686031e-02  5.78604685e-03\n",
      " -8.59186146e-03  4.74418374e-03  1.54720917e-02 -6.42325589e-03\n",
      " -1.58430226e-02 -2.98779178e-02 -1.54255824e-02  3.28209326e-02\n",
      "  2.43825577e-02  1.32907031e-03  1.80883706e-02 -2.72825565e-02\n",
      "  9.28488653e-03 -7.39418622e-03 -7.98023026e-03  1.84244160e-02\n",
      " -9.45350039e-04 -1.16825579e-02  1.15813862e-03 -2.10464321e-04\n",
      " -3.00813979e-03  4.75407019e-02 -8.32790602e-03  4.11511678e-03\n",
      " -1.25604663e-02  8.92209262e-03  7.64534995e-03 -2.65965052e-02\n",
      "  6.58837147e-03 -1.12011610e-02 -9.68022924e-03  1.60023291e-02\n",
      "  1.61629519e-04  3.20906974e-02 -1.59848798e-02  1.14162825e-02\n",
      " -2.40430199e-02  5.39906919e-02 -4.80814092e-03  3.02209193e-03\n",
      "  5.89418598e-03 -3.94418649e-03 -2.68058274e-02 -8.98256153e-03\n",
      " -2.94616278e-02  3.90697829e-03  4.68255766e-03  3.96162830e-03\n",
      " -2.68069748e-02 -2.68395394e-02 -9.76740339e-05  5.67557989e-03\n",
      "  4.43197712e-02 -1.38953477e-02 -3.69888335e-01  1.04639539e-02\n",
      "  1.55372089e-02 -1.35093015e-02 -8.09988379e-02  2.67802346e-02\n",
      "  2.21941881e-02 -7.86627829e-03 -1.00313956e-02  1.52511625e-02\n",
      "  1.45744160e-01  4.61395411e-03  7.26162829e-03  3.14453505e-02\n",
      " -7.95465056e-03 -1.25395320e-02  6.95348764e-03 -2.48023286e-03\n",
      "  6.17325725e-03  1.26546472e-02  1.03558144e-02 -1.21616265e-02\n",
      " -1.27907039e-03 -1.99348871e-02 -9.01860371e-03  4.25581448e-03\n",
      "  7.45790750e-02  1.02186035e-02 -9.93953645e-03  1.72848776e-02\n",
      " -1.03779081e-02  1.46616297e-02 -3.75465187e-03 -2.26953458e-02\n",
      "  5.36046689e-04  6.64511696e-02 -2.53790785e-02  5.80627881e-02\n",
      " -1.42732579e-02  9.22453254e-02 -1.12825576e-02 -2.51837187e-02\n",
      "  3.90697736e-03  5.96395321e-03 -3.02476659e-02  2.63883732e-02\n",
      " -1.69488378e-02  7.39418576e-03  1.60662793e-02 -1.68313961e-02\n",
      " -8.25814065e-03 -1.36965141e-02  7.30697624e-03  1.63453538e-02\n",
      " -4.15407047e-02  1.05633713e-01  1.53325591e-02  6.63023209e-03\n",
      "  3.93279046e-02 -1.27697680e-02 -5.95697621e-03 -8.67441762e-03\n",
      "  1.58593040e-02  9.42093134e-03 -4.15697647e-03  1.34639572e-02\n",
      " -4.10383604e-02 -2.82325619e-03 -2.43790708e-02 -4.02325485e-03\n",
      "  1.65058132e-02  4.21395432e-03  1.25813941e-02  1.64744183e-02\n",
      " -2.81162816e-03  1.34813897e-02 -8.19302350e-03 -7.04767322e-03\n",
      "  1.67139638e-02  1.43581396e-02  1.20023256e-02  4.96162800e-03\n",
      "  1.76325571e-02 -7.07674446e-03 -4.24197726e-02 -2.34697610e-02\n",
      " -1.86058115e-02 -2.32790736e-03  2.98906974e-02  1.53604464e-03\n",
      "  1.95941851e-02 -2.67104693e-02 -1.12453466e-02 -2.54534930e-03\n",
      " -4.29302268e-03  3.56558077e-02 -4.36046888e-04 -8.16406980e-02\n",
      "  5.04779041e-01 -2.18813960e-02  1.15883695e-02  2.14848872e-02\n",
      "  7.80581404e-03  1.55116236e-02 -1.11523261e-02  4.61628864e-04\n",
      "  1.72918607e-02  1.43034859e-02  2.05546506e-02 -8.23488459e-03\n",
      " -3.16290706e-02 -4.83953534e-03 -1.82697661e-02  2.02907110e-03\n",
      " -3.51163093e-04  1.10220918e-02 -8.54755938e-02 -2.68255756e-03\n",
      "  1.83174424e-02  1.91116314e-02 -4.73488262e-03 -8.08255840e-03\n",
      "  1.37906978e-02 -7.76046468e-03 -2.82767452e-02 -2.99069774e-03\n",
      "  1.06569799e-02 -5.99999772e-03  1.11883730e-02  4.28720983e-03\n",
      " -3.12255807e-02 -8.07186142e-02  8.59302282e-03 -8.11744668e-03\n",
      " -5.36279054e-03  1.87046509e-02 -1.10972092e-01 -3.07988375e-02\n",
      "  9.47441999e-03 -1.03662787e-02  1.16337193e-02  3.22093032e-02\n",
      " -2.69790720e-02  2.25430205e-02 -1.49802361e-02 -1.05290683e-02\n",
      " -4.36534919e-02  6.34883530e-04 -2.83197612e-02 -1.37674408e-02\n",
      " -1.50220934e-02  1.30851150e-01 -1.22430259e-02  2.38767453e-02]\n"
     ]
    }
   ],
   "source": [
    "v = vectorized_training['George_Washington']['vector']\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the vectorized_training into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDict(d, percent):\n",
    "    split_idx = int(len(d) * percent)\n",
    "    d1 = dict(list(d.items())[: split_idx])\n",
    "    d2 = dict(list(d.items())[split_idx:])                \n",
    "\n",
    "    return d1, d2\n",
    "\n",
    "vectorized_training_test, vectorized_training_train = splitDict(vectorized_training, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342239"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_training_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the data\n",
    "import numpy as np\n",
    "\n",
    "def encode_data(vectorized_data):\n",
    "    X = np.array([vectorized_data[article]['vector'] for article in vectorized_data])\n",
    "    y = np.array([[(1 if occupation in vectorized_data[article]['occupations'] else 0)\n",
    "                        for occupation in occupations ] for article in vectorized_data])\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = encode_data(vectorized_training_train)\n",
    "X_test, y_test = encode_data(vectorized_training_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342239, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342239, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using keras, define a sequential neural network with two layers. Use categorical_crossentropy as a loss function and softmax as the activation function of the output layer\n",
    "\n",
    "You can look into the documentation here: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=300))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308015 samples, validate on 34224 samples\n",
      "Epoch 1/50\n",
      "308015/308015 [==============================] - 3s 10us/step - loss: 3.5608 - acc: 0.4881 - val_loss: 2.0247 - val_acc: 0.6362\n",
      "Epoch 2/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 2.3868 - acc: 0.6581 - val_loss: 1.7224 - val_acc: 0.6907\n",
      "Epoch 3/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 2.1847 - acc: 0.6880 - val_loss: 1.6056 - val_acc: 0.7125\n",
      "Epoch 4/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 2.0853 - acc: 0.7033 - val_loss: 1.5498 - val_acc: 0.7234\n",
      "Epoch 5/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 2.0255 - acc: 0.7115 - val_loss: 1.5037 - val_acc: 0.7321\n",
      "Epoch 6/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9833 - acc: 0.7176 - val_loss: 1.4793 - val_acc: 0.7359\n",
      "Epoch 7/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9517 - acc: 0.7213 - val_loss: 1.4538 - val_acc: 0.7409\n",
      "Epoch 8/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9250 - acc: 0.7251 - val_loss: 1.4335 - val_acc: 0.7466\n",
      "Epoch 9/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9036 - acc: 0.7273 - val_loss: 1.4188 - val_acc: 0.7452\n",
      "Epoch 10/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8846 - acc: 0.7293 - val_loss: 1.4096 - val_acc: 0.7491\n",
      "Epoch 11/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8676 - acc: 0.7324 - val_loss: 1.3920 - val_acc: 0.7537\n",
      "Epoch 12/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8522 - acc: 0.7333 - val_loss: 1.3919 - val_acc: 0.7550\n",
      "Epoch 13/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8387 - acc: 0.7349 - val_loss: 1.3776 - val_acc: 0.7560\n",
      "Epoch 14/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8256 - acc: 0.7372 - val_loss: 1.3729 - val_acc: 0.7587\n",
      "Epoch 15/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8138 - acc: 0.7383 - val_loss: 1.3733 - val_acc: 0.7553\n",
      "Epoch 16/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8025 - acc: 0.7391 - val_loss: 1.3637 - val_acc: 0.7564\n",
      "Epoch 17/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.7916 - acc: 0.7408 - val_loss: 1.3510 - val_acc: 0.7603\n",
      "Epoch 18/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.7818 - acc: 0.7417 - val_loss: 1.3484 - val_acc: 0.7622\n",
      "Epoch 19/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7721 - acc: 0.7434 - val_loss: 1.3472 - val_acc: 0.7599\n",
      "Epoch 20/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.7634 - acc: 0.7436 - val_loss: 1.3448 - val_acc: 0.7615\n",
      "Epoch 21/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7554 - acc: 0.7450 - val_loss: 1.3347 - val_acc: 0.7649\n",
      "Epoch 22/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7462 - acc: 0.7463 - val_loss: 1.3367 - val_acc: 0.7639\n",
      "Epoch 23/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7388 - acc: 0.7467 - val_loss: 1.3338 - val_acc: 0.7641\n",
      "Epoch 24/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7308 - acc: 0.7481 - val_loss: 1.3379 - val_acc: 0.7646\n",
      "Epoch 25/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7240 - acc: 0.7486 - val_loss: 1.3341 - val_acc: 0.7644\n",
      "Epoch 26/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7173 - acc: 0.7494 - val_loss: 1.3279 - val_acc: 0.7634\n",
      "Epoch 27/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7097 - acc: 0.7500 - val_loss: 1.3268 - val_acc: 0.7610\n",
      "Epoch 28/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7030 - acc: 0.7510 - val_loss: 1.3203 - val_acc: 0.7664\n",
      "Epoch 29/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6968 - acc: 0.7518 - val_loss: 1.3266 - val_acc: 0.7640\n",
      "Epoch 30/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.6907 - acc: 0.7525 - val_loss: 1.3202 - val_acc: 0.7654\n",
      "Epoch 31/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6837 - acc: 0.7533 - val_loss: 1.3224 - val_acc: 0.7615\n",
      "Epoch 32/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6777 - acc: 0.7537 - val_loss: 1.3208 - val_acc: 0.7650\n",
      "Epoch 33/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6719 - acc: 0.7541 - val_loss: 1.3257 - val_acc: 0.7629\n",
      "Epoch 34/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6654 - acc: 0.7554 - val_loss: 1.3239 - val_acc: 0.7624\n",
      "Epoch 35/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6594 - acc: 0.7557 - val_loss: 1.3201 - val_acc: 0.7618\n",
      "Epoch 36/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6540 - acc: 0.7566 - val_loss: 1.3231 - val_acc: 0.7631\n",
      "Epoch 37/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6487 - acc: 0.7568 - val_loss: 1.3197 - val_acc: 0.7663\n",
      "Epoch 38/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6427 - acc: 0.7581 - val_loss: 1.3195 - val_acc: 0.7684\n",
      "Epoch 39/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6375 - acc: 0.7579 - val_loss: 1.3150 - val_acc: 0.7657\n",
      "Epoch 40/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6323 - acc: 0.7581 - val_loss: 1.3244 - val_acc: 0.7619\n",
      "Epoch 41/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6270 - acc: 0.7595 - val_loss: 1.3234 - val_acc: 0.7617\n",
      "Epoch 42/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6214 - acc: 0.7601 - val_loss: 1.3270 - val_acc: 0.7601\n",
      "Epoch 43/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6162 - acc: 0.7604 - val_loss: 1.3214 - val_acc: 0.7638\n",
      "Epoch 44/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6115 - acc: 0.7606 - val_loss: 1.3241 - val_acc: 0.7622\n",
      "Epoch 45/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6061 - acc: 0.7616 - val_loss: 1.3275 - val_acc: 0.7599\n",
      "Epoch 46/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6012 - acc: 0.7622 - val_loss: 1.3222 - val_acc: 0.7651\n",
      "Epoch 47/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5964 - acc: 0.7628 - val_loss: 1.3247 - val_acc: 0.7631\n",
      "Epoch 48/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5910 - acc: 0.7632 - val_loss: 1.3250 - val_acc: 0.7668\n",
      "Epoch 49/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5868 - acc: 0.7636 - val_loss: 1.3247 - val_acc: 0.7598\n",
      "Epoch 50/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5814 - acc: 0.7645 - val_loss: 1.3295 - val_acc: 0.7646\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=1024, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Complete the function predict: output the list of occupations where the corresponding neuron on the output layer of our model has a value > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q177220', 'Q639669', 'Q33999'}\n"
     ]
    }
   ],
   "source": [
    "def predict_nn(model, article_name, vectorized_dataset):\n",
    "    input_vector = vectorized_dataset[article_name]['vector'].reshape((1, 300))\n",
    "    scores = model.predict(input_vector).reshape(100)\n",
    "    predictions = np.where(scores > 0.1)[0]\n",
    "#     print(scores[predictions])\n",
    "    return set(np.array(occupations)[predictions])\n",
    "\n",
    "print(predict_nn(model, 'Elvis_Presley', vectorized_training))\n",
    "# should be {'Q177220'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(vectorized_training, model):\n",
    "    nexample = 0\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for article_name in vectorized_training:\n",
    "        prediction = predict_nn(model, article_name, vectorized_training)\n",
    "        p = frozenset(prediction)\n",
    "        g = frozenset(vectorized_training[article_name]['occupations'])\n",
    "        accuracy += 1.*len(p & g) / len(p | g)\n",
    "        nexample += 1\n",
    "    return accuracy / nexample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7048576643356244\n",
      "0.6662116943899452\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_nn(vectorized_training_train, model))\n",
    "print(evaluate_nn(vectorized_training_test, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Your approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, GRU, Dropout, Conv1D, MaxPooling1D, MaxPooling1D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dataset into summaries, titles and occupations\n",
    "def parse(dataset):\n",
    "    titles = []\n",
    "    summaries = []\n",
    "    occs = []\n",
    "    for example in dataset:\n",
    "        titles.append(example['title'])\n",
    "        summaries.append(example['summary'])        \n",
    "        if 'occupations' in example:\n",
    "            occs.append(example['occupations'])\n",
    "    return titles, summaries, occs\n",
    "    \n",
    "titles_train, summaries_train, occs_train = parse(training_set)\n",
    "\n",
    "s = int(len(titles_train) * 0.8)\n",
    "titles_train_train, summaries_train_train, occs_train_train = titles_train[:s], summaries_train[:s], occs_train[:s]\n",
    "titles_train_test, summaries_train_test, occs_train_test = titles_train[s:], summaries_train[s:], occs_train[s:]\n",
    "\n",
    "titles_test, summaries_test, occs_test = parse(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 370295 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(titles_train_train)\n",
    "maxlen = 300\n",
    "training_samples = int(n_samples * 0.85)\n",
    "validation_samples = n_samples - training_samples\n",
    "max_words = 20000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(summaries_train_train)\n",
    "\n",
    "# convert text to sequences\n",
    "sequences =  tokenizer.texts_to_sequences(summaries_train_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(summaries_train_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found', len(word_index), 'unique tokens.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_occs_to_labels(occupations, occs_train):\n",
    "    labels = []\n",
    "    for i in range(len(occs_train)):\n",
    "        label = []\n",
    "        for occ in occupations:\n",
    "            if occ in occs_train[i]:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "        labels.append(label)\n",
    "    return np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (342333, 300)\n",
      "Shape of label tensor: (342333, 100)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "data_test = pad_sequences(sequences_test, maxlen=maxlen)\n",
    "labels = convert_occs_to_labels(occupations, occs_train_train)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# shuffle the data\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# split into training and testing set\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = 'glove.6B'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.300d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found', len(embeddings_index), 'word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding matrix to load into embedding layer\n",
    "embedding_dim = 300\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 300, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 300, 32)           28832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 100, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 33, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 33, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 33, 128)           24704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_32 (GRU)                 (None, 11, 50)            26850     \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 11, 50)            0         \n",
      "_________________________________________________________________\n",
      "gru_33 (GRU)                 (None, 11, 50)            15150     \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 11, 50)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 550)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 128)               70528     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 6,230,996\n",
      "Trainable params: 6,230,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "\n",
    "model.add(Conv1D(32,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv1D(64,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv1D(128,kernel_size=3,padding='same',activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(GRU(50,return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(GRU(50,return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# model.add(GRU(128,\n",
    "#               dropout=0.1,\n",
    "#               recurrent_dropout=0.5,\n",
    "#               return_sequences=True))\n",
    "# model.add(GRU(128,\n",
    "#               dropout=0.1,\n",
    "#               recurrent_dropout=0.3,\n",
    "#               return_sequences=True\n",
    "#              ))\n",
    "\n",
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Glove embedding in the model\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False # we will not update this layer during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 290983 samples, validate on 51350 samples\n",
      "Epoch 1/100\n",
      "290983/290983 [==============================] - 31s 107us/step - loss: 3.9997 - acc: 0.4025 - val_loss: 2.6652 - val_acc: 0.6255\n",
      "Epoch 2/100\n",
      "290983/290983 [==============================] - 27s 92us/step - loss: 2.6085 - acc: 0.6288 - val_loss: 2.2782 - val_acc: 0.6953\n",
      "Epoch 3/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 2.3553 - acc: 0.6791 - val_loss: 2.1379 - val_acc: 0.7205\n",
      "Epoch 4/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 2.2332 - acc: 0.7000 - val_loss: 2.0505 - val_acc: 0.7350\n",
      "Epoch 5/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 2.1558 - acc: 0.7114 - val_loss: 2.0029 - val_acc: 0.7369\n",
      "Epoch 6/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 2.1015 - acc: 0.7192 - val_loss: 1.9657 - val_acc: 0.7400\n",
      "Epoch 7/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 2.0596 - acc: 0.7247 - val_loss: 1.9342 - val_acc: 0.7455\n",
      "Epoch 8/100\n",
      "290983/290983 [==============================] - 27s 94us/step - loss: 2.0260 - acc: 0.7296 - val_loss: 1.9159 - val_acc: 0.7410\n",
      "Epoch 9/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 2.0014 - acc: 0.7322 - val_loss: 1.9003 - val_acc: 0.7511\n",
      "Epoch 10/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.9807 - acc: 0.7357 - val_loss: 1.8828 - val_acc: 0.7507\n",
      "Epoch 11/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.9631 - acc: 0.7384 - val_loss: 1.8756 - val_acc: 0.7468\n",
      "Epoch 12/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.9482 - acc: 0.7399 - val_loss: 1.8608 - val_acc: 0.7534\n",
      "Epoch 13/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.9343 - acc: 0.7414 - val_loss: 1.8527 - val_acc: 0.7549\n",
      "Epoch 14/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.9232 - acc: 0.7424 - val_loss: 1.8457 - val_acc: 0.7573\n",
      "Epoch 15/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.9144 - acc: 0.7436 - val_loss: 1.8412 - val_acc: 0.7522\n",
      "Epoch 16/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.9046 - acc: 0.7449 - val_loss: 1.8382 - val_acc: 0.7581\n",
      "Epoch 17/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.8946 - acc: 0.7463 - val_loss: 1.8244 - val_acc: 0.7540\n",
      "Epoch 18/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.8868 - acc: 0.7477 - val_loss: 1.8278 - val_acc: 0.7610\n",
      "Epoch 19/100\n",
      "290983/290983 [==============================] - 27s 93us/step - loss: 1.8786 - acc: 0.7475 - val_loss: 1.8171 - val_acc: 0.7547\n",
      "Epoch 20/100\n",
      "290983/290983 [==============================] - 26s 91us/step - loss: 1.8732 - acc: 0.7487 - val_loss: 1.8187 - val_acc: 0.7575\n",
      "Epoch 21/100\n",
      "290983/290983 [==============================] - 26s 91us/step - loss: 1.8664 - acc: 0.7496 - val_loss: 1.8162 - val_acc: 0.7594\n",
      "Epoch 22/100\n",
      "290983/290983 [==============================] - 27s 92us/step - loss: 1.8626 - acc: 0.7496 - val_loss: 1.8121 - val_acc: 0.7582\n",
      "Epoch 23/100\n",
      " 98000/290983 [=========>....................] - ETA: 18s - loss: 1.8581 - acc: 0.7504"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-e99f3ac200e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "    epochs=100,\n",
    "    callbacks=callbacks,\n",
    "    batch_size=1000,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q177220', 'Q10800557', 'Q28389', 'Q486748', 'Q855091']\n",
      "[0.10287087 0.7062845 ]\n",
      "[0.7062845]\n",
      "[0.7062845]\n",
      "({'Q82955', 'Q39631'}, {'Q82955', 'Q39631'}, {'Q82955', 'Q39631'})\n"
     ]
    }
   ],
   "source": [
    "def predict_nn_2(model, input_vector, print_score = False):\n",
    "    \n",
    "    scores = model.predict(input_vector).reshape(100)\n",
    "    predictions1 = np.where(scores > 0.1)[0]\n",
    "    predictions2 = np.where(scores > 0.2)[0]\n",
    "    predictions3 = np.where(scores > 0.3)[0]\n",
    "    if print_score:\n",
    "        print(scores[predictions1])\n",
    "        print(scores[predictions2])\n",
    "        print(scores[predictions3])\n",
    "    res1 = set(np.array(occupations)[predictions1])\n",
    "    res2 = set(np.array(occupations)[predictions1])\n",
    "    res3 = set(np.array(occupations)[predictions1])\n",
    "    return res1, res2, res3\n",
    "\n",
    "title = 'Elvis_Presley'\n",
    "idx = titles_train.index(title)\n",
    "input_vector = data[idx].reshape(1, maxlen)\n",
    "\n",
    "print(predict_nn_2(model, input_vector, print_score=True))\n",
    "# should be {'Q177220'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85584"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'accuracy1' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-f971ead1b930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# print(evaluate_nn_2(titles_train, summaries_train, occs_train, model))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_nn_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccs_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-76-f971ead1b930>\u001b[0m in \u001b[0;36mevaluate_nn_2\u001b[0;34m(titles, input_vectors, occs, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mp3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0maccuracy1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnexample\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0maccuracy2\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnexample\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp2\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0maccuracy3\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnexample\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp3\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp3\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'accuracy1' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def evaluate_nn_2(titles, input_vectors, occs, model):\n",
    "    nexample = len(titles)\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for i in range(len(titles)):        \n",
    "        input_vector = input_vectors[i].reshape(1, -1)\n",
    "        prediction1, prediction2, prediction3 = predict_nn_2(model, input_vector)\n",
    "        p1 = frozenset(prediction1)\n",
    "        p2 = frozenset(prediction2)\n",
    "        p3 = frozenset(prediction3)\n",
    "        g = frozenset(occs[i])\n",
    "        accuracy1 += 1. / nexample * len(p1 & g) / len(p1 | g)\n",
    "        accuracy2 += 1. / nexample * len(p2 & g) / len(p2 | g)\n",
    "        accuracy3 += 1. / nexample * len(p3 & g) / len(p3 | g)\n",
    "        if i % 100 == 0:\n",
    "            print(i * 100 / nexample, \" : \", accuracy1)\n",
    "            print(i * 100 / nexample, \" : \", accuracy2)\n",
    "            print(i * 100 / nexample, \" : \", accuracy3)\n",
    "    return accuracy1, accuracy2, accuracy3\n",
    "\n",
    "# print(evaluate_nn_2(titles_train, summaries_train, occs_train, model))\n",
    "print(evaluate_nn_2(titles_train_test, data_test, occs_train_test, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluate_nn_2(titles_train_train, data, occs_train_train, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IMPORTANT*** Output format of requested file 'results.json.gz': each line must be a json string representing a dictionnary:\n",
    "> ```{ 'title': THE_ARTICLE_NAME, 'prediction': [THE_LIST_OF_OCCUPATIONS]}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example if testset_solutions is a dictionnary: article_name (key) -> prediction_list (value) use this function:\n",
    "def export(testset_solutions):\n",
    "    with gzip.open('results.json.gz', 'wt') as output:\n",
    "        for article in testset_solutions:\n",
    "            output.write(json.dumps({'title':article, 'prediction':testset_solutions[article]}) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
