{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "## Question 0 - Get common wikidata occupations\n",
    "\n",
    "> Write a sparql query that retrieves the top 100 occupations on wikidata (wikidata property P106).\n",
    "\n",
    "You may use the interface https://query.wikidata.org/ to try different queries. Here are some example sparql queries: https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/queries/examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT ?o (COUNT(?person) AS ?count) WHERE \n",
    "{\n",
    "   ?person wdt:P106 ?o\n",
    "}\n",
    "GROUP BY ?o\n",
    "ORDER BY DESC(?count)\n",
    "LIMIT 100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following assertion should pass if your answer is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "occupations = ['Q82955', 'Q937857', 'Q36180', 'Q33999', 'Q1650915', 'Q1028181', 'Q1930187', 'Q177220', 'Q1622272', 'Q49757', 'Q36834', 'Q40348', 'Q47064', 'Q639669', 'Q10800557', 'Q201788', 'Q2526255', 'Q43845', 'Q28389', 'Q42973', 'Q10871364', 'Q39631', 'Q193391', 'Q482980', 'Q483501', 'Q11513337', 'Q3665646', 'Q12299841', 'Q19204627', 'Q16533', 'Q81096', 'Q11774891', 'Q188094', 'Q1281618', 'Q333634', 'Q189290', 'Q250867', 'Q33231', 'Q2259451', 'Q42603', 'Q628099', 'Q37226', 'Q2309784', 'Q901', 'Q2066131', 'Q6625963', 'Q10798782', 'Q2374149', 'Q170790', 'Q4610556', 'Q185351', 'Q486748', 'Q3055126', 'Q753110', 'Q4964182', 'Q169470', 'Q158852', 'Q1234713', 'Q14089670', 'Q10873124', 'Q3282637', 'Q593644', 'Q947873', 'Q13414980', 'Q131524', 'Q11338576', 'Q15117302', 'Q488205', 'Q14467526', 'Q183945', 'Q10843402', 'Q13382576', 'Q13141064', 'Q214917', 'Q855091', 'Q644687', 'Q19595175', 'Q121594', 'Q2865819', 'Q16010345', 'Q1231865', 'Q2405480', 'Q350979', 'Q3400985', 'Q13365117', 'Q10833314', 'Q3621491', 'Q15981151', 'Q212980', 'Q16145150', 'Q1792450', 'Q15296811', 'Q15627169', 'Q2306091', 'Q4263842', 'Q806798', 'Q5716684', 'Q2516866', 'Q3387717', 'Q131512']\n",
    "\n",
    "def evalSparql(query):\n",
    "    return requests.post('https://query.wikidata.org/sparql', data=query, headers={\n",
    "        'content-type': 'application/sparql-query',\n",
    "        'accept': 'application/json',\n",
    "        'user-agent': 'User:Tpt'\n",
    "    }).json()['results']['bindings']\n",
    "\n",
    "myOccupations = [val['o']['value'].replace('http://www.wikidata.org/entity/', '') \n",
    "                 for val in evalSparql(query)]\n",
    "assert(frozenset(occupations) == frozenset(myOccupations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupations labels\n",
    "\n",
    "We load the labels of the occupations from Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q82955': 'politician', 'Q121594': 'professor', 'Q177220': 'singer', 'Q169470': 'physicist', 'Q170790': 'mathematician', 'Q81096': 'engineer', 'Q201788': 'historian', 'Q188094': 'economist', 'Q212980': 'psychologist', 'Q214917': 'playwright', 'Q131524': 'entrepreneur', 'Q183945': 'record producer', 'Q193391': 'diplomat', 'Q189290': 'military officer', 'Q185351': 'jurist', 'Q350979': 'zoologist', 'Q483501': 'artist', 'Q482980': 'author', 'Q333634': 'translator', 'Q158852': 'conductor', 'Q486748': 'pianist', 'Q488205': 'singer-songwriter', 'Q250867': 'Catholic priest', 'Q593644': 'chemist', 'Q639669': 'musician', 'Q644687': 'illustrator', 'Q628099': 'association football manager', 'Q855091': 'guitarist', 'Q937857': 'association football player', 'Q947873': 'television presenter', 'Q806798': 'banker', 'Q1028181': 'painter', 'Q753110': 'songwriter', 'Q1234713': 'theologian', 'Q1281618': 'sculptor', 'Q1622272': 'university teacher', 'Q1792450': 'art historian', 'Q1650915': 'researcher', 'Q1930187': 'journalist', 'Q2306091': 'sociologist', 'Q2374149': 'botanist', 'Q2526255': 'film director', 'Q2516866': 'publisher', 'Q2066131': 'athlete', 'Q2405480': 'voice actor', 'Q1231865': 'pedagogue', 'Q2865819': 'opera singer', 'Q2259451': 'stage actor', 'Q3282637': 'film producer', 'Q3387717': 'theatre director', 'Q3055126': 'entomologist', 'Q3400985': 'academic', 'Q3665646': 'basketball player', 'Q3621491': 'archaeologist', 'Q4610556': 'model', 'Q4263842': 'literary critic', 'Q4964182': 'philosopher', 'Q5716684': 'dancer', 'Q6625963': 'novelist', 'Q10843402': 'swimmer', 'Q10833314': 'tennis player', 'Q10871364': 'baseball player', 'Q10798782': 'television actor', 'Q10873124': 'chess player', 'Q10800557': 'film actor', 'Q11338576': 'boxer', 'Q11513337': 'athletics competitor', 'Q2309784': 'sport cyclist', 'Q11774891': 'ice hockey player', 'Q12299841': 'cricketer', 'Q13141064': 'badminton player', 'Q13365117': 'handball player', 'Q13414980': 'Australian rules footballer', 'Q14089670': 'rugby union player', 'Q14467526': 'linguist', 'Q15117302': 'volleyball player', 'Q15627169': 'trade unionist', 'Q15981151': 'jazz musician', 'Q16010345': 'performer', 'Q131512': 'agriculturer', 'Q13382576': 'rower', 'Q19204627': 'American football player', 'Q15296811': 'drawer', 'Q19595175': 'amateur wrestler', 'Q16145150': 'music pedagogue', 'Q901': 'scientist', 'Q33999': 'actor', 'Q33231': 'photographer', 'Q36834': 'composer', 'Q16533': 'judge', 'Q40348': 'lawyer', 'Q36180': 'writer', 'Q42973': 'architect', 'Q43845': 'businessperson', 'Q39631': 'physician', 'Q28389': 'screenwriter', 'Q42603': 'priest', 'Q49757': 'poet', 'Q37226': 'teacher', 'Q47064': 'military personnel'}\n"
     ]
    }
   ],
   "source": [
    "occupations_label = {}\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT ?o ?oLabel \n",
    "WHERE { \n",
    "    VALUES ?o { %s } \n",
    "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "}\"\"\"% ' '.join('wd:' + o for o in occupations)\n",
    "\n",
    "for result in evalSparql(query):\n",
    "    occupations_label[result['o']['value'].replace('http://www.wikidata.org/entity/', '')] = result['oLabel']['value']\n",
    "\n",
    "print(occupations_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load *all* the labels of the occupations from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q82955': ['politician', 'political leader', 'polit.', 'political figure'], 'Q121594': ['professor', 'Prof.'], 'Q177220': ['singer', 'vocalist'], 'Q169470': ['physicist'], 'Q170790': ['mathematician'], 'Q81096': ['engineer'], 'Q201788': ['historian', 'historians', 'historiographer'], 'Q188094': ['economist'], 'Q212980': ['psychologist'], 'Q214917': ['playwright', 'dramatist', 'scriptwriter', 'playwrite', 'Playwright, dramatist'], 'Q131524': ['entrepreneur'], 'Q183945': ['record producer', 'music producer'], 'Q193391': ['diplomat'], 'Q189290': ['military officer', 'army officer', 'officer'], 'Q185351': ['jurist'], 'Q350979': ['zoologist', 'zooligist'], 'Q483501': ['artist'], 'Q482980': ['author'], 'Q333634': ['translator'], 'Q158852': ['conductor', 'Conducting'], 'Q486748': ['pianist'], 'Q488205': ['singer-songwriter', 'singer/songwriter', 'singer songwriter', 'singersongwriter'], 'Q250867': ['Catholic priest', 'Roman Catholic priest', 'Catholic presbyter', 'Roman Catholic presbyter'], 'Q593644': ['chemist', 'chemists'], 'Q639669': ['musician'], 'Q644687': ['illustrator'], 'Q628099': ['association football manager', 'football manager', 'association football coach', 'football coach', 'soccer coach', 'soccer manager'], 'Q855091': ['guitarist', 'guitar player'], 'Q937857': ['association football player', 'footballer', 'football player', 'association footballer', 'soccer player'], 'Q947873': ['television presenter', 'TV presenter', 'hostess', 'TV host', 'TV personality', 'host', 'television personality', 'television host'], 'Q806798': ['banker', 'Private Banker', 'private sector banker'], 'Q1028181': ['painter'], 'Q753110': ['songwriter', 'song writer'], 'Q1234713': ['theologian', 'religious scholar'], 'Q1281618': ['sculptor'], 'Q1622272': ['university teacher', 'lecturer', 'university teachers', 'college lecturer', 'college professor'], 'Q1792450': ['art historian'], 'Q1650915': ['researcher'], 'Q1930187': ['journalist', 'journo'], 'Q2306091': ['sociologist'], 'Q2374149': ['botanist', 'botany', 'plant scientist'], 'Q2526255': ['film director', 'director', 'movie director'], 'Q2516866': ['publisher'], 'Q2066131': ['athlete', 'sportsperson', 'sportsman', 'sportswoman'], 'Q2405480': ['voice actor', 'voice actress', 'voice artist'], 'Q1231865': ['pedagogue', 'educationalist'], 'Q2865819': ['opera singer'], 'Q2259451': ['stage actor', 'stage actress', 'theater actor', 'theater actress', 'theatre actor', 'theatre actress'], 'Q3282637': ['film producer', 'producer', 'movie producer'], 'Q3387717': ['theatre director', 'theater director', 'stage director'], 'Q3055126': ['entomologist'], 'Q3400985': ['academic', 'college graduates', 'university graduates'], 'Q3665646': ['basketball player', 'professional basketball player', 'basketballer'], 'Q3621491': ['archaeologist', 'archeologist'], 'Q4610556': ['model', 'fashion model', 'mannequin'], 'Q4263842': ['literary critic', 'book critic', 'literary critique'], 'Q4964182': ['philosopher'], 'Q5716684': ['dancer'], 'Q6625963': ['novelist'], 'Q10843402': ['swimmer'], 'Q10833314': ['tennis player'], 'Q10871364': ['baseball player'], 'Q10798782': ['television actor', 'actor', 'actress', 'television actress', 'TV actor', 'TV actress'], 'Q10873124': ['chess player'], 'Q10800557': ['film actor', 'film actress', 'movie actor', 'movie actress'], 'Q11338576': ['boxer', 'pugilist'], 'Q11513337': ['athletics competitor', 'track and field athlete', 'athlete (restricted sense)'], 'Q2309784': ['sport cyclist', 'racing cyclist', 'sport bicyclist', 'sport biker'], 'Q11774891': ['ice hockey player', 'hockey player'], 'Q12299841': ['cricketer', 'cricket player'], 'Q13141064': ['badminton player'], 'Q13365117': ['handball player', 'handballer'], 'Q13414980': ['Australian rules footballer', 'Australian footballer', 'Australian rules football player', 'Australian-rules football player'], 'Q14089670': ['rugby union player'], 'Q14467526': ['linguist', 'linguistic scholar'], 'Q15117302': ['volleyball player', 'volleyballer'], 'Q15627169': ['trade unionist', 'labor unionist', 'labour unionist'], 'Q15981151': ['jazz musician'], 'Q16010345': ['performer', 'performing artist', 'scenic artist'], 'Q131512': ['agriculturer', 'farmer', 'agriculturist', 'cultivator', 'grower', 'raiser'], 'Q13382576': ['rower', 'oarsman', 'oarswoman'], 'Q19204627': ['American football player', 'football player'], 'Q15296811': ['drawer', 'illustrator', 'draughtsperson', 'draughtsman', 'draftsperson', 'draftsman', 'draftswoman', 'drafter'], 'Q19595175': ['amateur wrestler', 'wrestler'], 'Q16145150': ['music pedagogue', 'music teacher'], 'Q901': ['scientist', 'natural philosopher'], 'Q33999': ['actor', 'actors', 'actresses', 'actress'], 'Q33231': ['photographer'], 'Q36834': ['composer'], 'Q16533': ['judge', 'magistrate', 'justice', 'judges', 'justices'], 'Q40348': ['lawyer', 'attorney', 'Jurisprudente'], 'Q36180': ['writer', 'author', 'writers', 'authors'], 'Q42973': ['architect'], 'Q43845': ['businessperson', 'businessman', 'dealer', 'business person', 'business woman', 'businesswoman', 'business man'], 'Q39631': ['physician', 'physicians'], 'Q28389': ['screenwriter', 'writer', 'screen writer', 'scriptwriter', 'scenarist', 'film writer', 'tv writer', 'script writer'], 'Q42603': ['priest', 'priestess', 'reverend'], 'Q49757': ['poet', 'bard', 'poetess'], 'Q37226': ['teacher', 'professor', 'educator', 'schoolmaster', 'schoolmistress', 'school teacher'], 'Q47064': ['military personnel']}\n"
     ]
    }
   ],
   "source": [
    "occupations_labels = {k: [v] for k, v in occupations_label.items()}\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT ?o ?altLabel \n",
    "WHERE {\n",
    "  VALUES ?o { %s }\n",
    "  ?o skos:altLabel ?altLabel . FILTER (lang(?altLabel) = \"en\")\n",
    "}\"\"\" % ' '.join('wd:' + o for o in occupations) \n",
    "\n",
    "for result in evalSparql(query):\n",
    "    occupations_labels[result['o']['value'].replace('http://www.wikidata.org/entity/', '')].append(result['altLabel']['value'])\n",
    "\n",
    "print(occupations_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia articles\n",
    "\n",
    "Here we load the training and the testing sets. To save memory space we use a generator that will read the file each time we iterate over the training or the testing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "\n",
    "def loadJson(filename):\n",
    "    with gzip.open(filename, 'rt') as fp:\n",
    "        for line in fp:\n",
    "            yield json.loads(line)\n",
    "\n",
    "class MakeIter(object):\n",
    "    def __init__(self, generator_func, **kwargs):\n",
    "        self.generator_func = generator_func\n",
    "        self.kwargs = kwargs\n",
    "    def __iter__(self):\n",
    "        return self.generator_func(**self.kwargs)\n",
    "\n",
    "training_set = MakeIter(loadJson, filename='wiki-train.json.gz')\n",
    "testing_set = MakeIter(loadJson, filename='wiki-test.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract occupations from summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Dictionnary extraction\n",
    "\n",
    "> Using ```occupations_labels``` dictionnary, identify all occupations for each articles. Complete the function below to evaluate the accuracy of such approach. It will serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4842586814146957"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_occ = dict()\n",
    "for key, occs in occupations_labels.items():\n",
    "    for occ in occs:\n",
    "        label_to_occ[occ.lower()] = key\n",
    "\n",
    "def predict_dictionnary(example, occupations_labels):\n",
    "    occs = []\n",
    "    summary = example['summary'].lower()\n",
    "    labels = label_to_occ.keys()\n",
    "    for label in labels:\n",
    "        if label in summary:\n",
    "            occs.append(label_to_occ[label])\n",
    "    return occs\n",
    "    \n",
    "def evaluate_dictionnary(training_set, occupations_labels):\n",
    "    nexample = 0\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for example in training_set:\n",
    "        prediction = predict_dictionnary(example, occupations_labels)\n",
    "        p = frozenset(prediction)\n",
    "        g = frozenset(example['occupations'])\n",
    "        accuracy += 1.*len(p & g) / len(p | g)\n",
    "        nexample += 1\n",
    "    return accuracy / nexample\n",
    "\n",
    "evaluate_dictionnary(training_set, occupations_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the articles \"summary\" and we take the average of the word vectors.\n",
    "This is done with spacy loaded with the fast text vectors.\n",
    "To do the installation/loading [takes 8-10 minutes, dl 1.2Go]\n",
    "```\n",
    "pip3 install spacy\n",
    "wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/cc.en.300.vec.gz\n",
    "python3 -m spacy init-model en /tmp/en_vectors_wiki_lg --vectors-loc cc.en.300.vec.gz\n",
    "rm cc.en.300.vec.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nlp = spacy.load('/tmp/en_vectors_wiki_lg')\n",
    "\n",
    "def vectorize(dataset, nlp):\n",
    "    result = {}\n",
    "    for example in dataset:\n",
    "        doc = nlp(example['summary'], disable=['parser', 'tagger'])\n",
    "        result[example['title']] = {}\n",
    "        result[example['title']]['vector'] = doc.vector\n",
    "        result[example['title']]['summary'] = example['summary']\n",
    "        if 'occupations' in example:\n",
    "            result[example['title']]['occupations'] = example['occupations']\n",
    "    return result\n",
    "    \n",
    "vectorized_training = vectorize(training_set, nlp)\n",
    "vectorized_testing = vectorize(testing_set, nlp)\n",
    "nlp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427798"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.45162819e-02 -2.45802402e-02 -4.59302496e-03 -4.09372151e-02\n",
      " -4.47662771e-02 -4.18604538e-03 -3.15232435e-03 -1.44802360e-02\n",
      " -1.68499984e-02 -3.69651243e-03 -1.16255814e-02  1.43651171e-02\n",
      "  2.02674349e-03 -5.88953542e-03 -2.17011590e-02  1.02302311e-02\n",
      " -2.49313917e-02 -5.65232616e-03 -2.25581434e-02  8.29069968e-03\n",
      " -1.44069805e-03  2.25197673e-02 -6.81395701e-04 -1.37232570e-02\n",
      " -1.26674427e-02 -3.35569866e-02  1.10627888e-02 -2.37208814e-03\n",
      " -2.30000000e-02  7.58616179e-02 -5.03487710e-04 -2.51116175e-02\n",
      "  9.26511642e-03 -2.52558179e-02 -1.51058156e-02 -9.51627828e-03\n",
      "  1.17523270e-02  1.22441910e-03  1.08139520e-03  3.39302444e-03\n",
      "  2.20116391e-03  1.46860480e-02 -1.43686021e-02  5.76395402e-03\n",
      "  1.74162779e-02 -4.76220921e-02 -1.72569733e-02 -1.49988411e-02\n",
      " -1.77732538e-02  1.58907007e-02 -7.23255938e-03  2.43825577e-02\n",
      " -2.73104683e-02 -3.67430188e-02 -1.48802334e-02 -1.34825567e-02\n",
      " -3.14348824e-02  1.95930228e-02 -6.68605033e-04 -9.24302172e-03\n",
      "  1.56976283e-04 -1.65674444e-02 -1.30372085e-02  6.16298130e-05\n",
      " -3.63139645e-03  2.74534873e-03 -1.62697677e-02 -4.70697694e-03\n",
      "  5.48139494e-03  4.39302297e-03  4.65523303e-02  2.29872130e-02\n",
      "  2.72058025e-02 -5.52790612e-03  2.19720937e-02 -4.41581383e-02\n",
      "  1.33255811e-03  1.20244222e-02  3.49267460e-02  3.76593024e-02\n",
      "  8.65232572e-03 -6.52325572e-03 -1.90407019e-02  1.03569757e-02\n",
      "  1.09301973e-03 -6.28488278e-03  3.98965068e-02 -3.81744131e-02\n",
      " -1.35965087e-02  1.74023230e-02 -1.48686031e-02  5.78604685e-03\n",
      " -8.59186146e-03  4.74418374e-03  1.54720917e-02 -6.42325589e-03\n",
      " -1.58430226e-02 -2.98779178e-02 -1.54255824e-02  3.28209326e-02\n",
      "  2.43825577e-02  1.32907031e-03  1.80883706e-02 -2.72825565e-02\n",
      "  9.28488653e-03 -7.39418622e-03 -7.98023026e-03  1.84244160e-02\n",
      " -9.45350039e-04 -1.16825579e-02  1.15813862e-03 -2.10464321e-04\n",
      " -3.00813979e-03  4.75407019e-02 -8.32790602e-03  4.11511678e-03\n",
      " -1.25604663e-02  8.92209262e-03  7.64534995e-03 -2.65965052e-02\n",
      "  6.58837147e-03 -1.12011610e-02 -9.68022924e-03  1.60023291e-02\n",
      "  1.61629519e-04  3.20906974e-02 -1.59848798e-02  1.14162825e-02\n",
      " -2.40430199e-02  5.39906919e-02 -4.80814092e-03  3.02209193e-03\n",
      "  5.89418598e-03 -3.94418649e-03 -2.68058274e-02 -8.98256153e-03\n",
      " -2.94616278e-02  3.90697829e-03  4.68255766e-03  3.96162830e-03\n",
      " -2.68069748e-02 -2.68395394e-02 -9.76740339e-05  5.67557989e-03\n",
      "  4.43197712e-02 -1.38953477e-02 -3.69888335e-01  1.04639539e-02\n",
      "  1.55372089e-02 -1.35093015e-02 -8.09988379e-02  2.67802346e-02\n",
      "  2.21941881e-02 -7.86627829e-03 -1.00313956e-02  1.52511625e-02\n",
      "  1.45744160e-01  4.61395411e-03  7.26162829e-03  3.14453505e-02\n",
      " -7.95465056e-03 -1.25395320e-02  6.95348764e-03 -2.48023286e-03\n",
      "  6.17325725e-03  1.26546472e-02  1.03558144e-02 -1.21616265e-02\n",
      " -1.27907039e-03 -1.99348871e-02 -9.01860371e-03  4.25581448e-03\n",
      "  7.45790750e-02  1.02186035e-02 -9.93953645e-03  1.72848776e-02\n",
      " -1.03779081e-02  1.46616297e-02 -3.75465187e-03 -2.26953458e-02\n",
      "  5.36046689e-04  6.64511696e-02 -2.53790785e-02  5.80627881e-02\n",
      " -1.42732579e-02  9.22453254e-02 -1.12825576e-02 -2.51837187e-02\n",
      "  3.90697736e-03  5.96395321e-03 -3.02476659e-02  2.63883732e-02\n",
      " -1.69488378e-02  7.39418576e-03  1.60662793e-02 -1.68313961e-02\n",
      " -8.25814065e-03 -1.36965141e-02  7.30697624e-03  1.63453538e-02\n",
      " -4.15407047e-02  1.05633713e-01  1.53325591e-02  6.63023209e-03\n",
      "  3.93279046e-02 -1.27697680e-02 -5.95697621e-03 -8.67441762e-03\n",
      "  1.58593040e-02  9.42093134e-03 -4.15697647e-03  1.34639572e-02\n",
      " -4.10383604e-02 -2.82325619e-03 -2.43790708e-02 -4.02325485e-03\n",
      "  1.65058132e-02  4.21395432e-03  1.25813941e-02  1.64744183e-02\n",
      " -2.81162816e-03  1.34813897e-02 -8.19302350e-03 -7.04767322e-03\n",
      "  1.67139638e-02  1.43581396e-02  1.20023256e-02  4.96162800e-03\n",
      "  1.76325571e-02 -7.07674446e-03 -4.24197726e-02 -2.34697610e-02\n",
      " -1.86058115e-02 -2.32790736e-03  2.98906974e-02  1.53604464e-03\n",
      "  1.95941851e-02 -2.67104693e-02 -1.12453466e-02 -2.54534930e-03\n",
      " -4.29302268e-03  3.56558077e-02 -4.36046888e-04 -8.16406980e-02\n",
      "  5.04779041e-01 -2.18813960e-02  1.15883695e-02  2.14848872e-02\n",
      "  7.80581404e-03  1.55116236e-02 -1.11523261e-02  4.61628864e-04\n",
      "  1.72918607e-02  1.43034859e-02  2.05546506e-02 -8.23488459e-03\n",
      " -3.16290706e-02 -4.83953534e-03 -1.82697661e-02  2.02907110e-03\n",
      " -3.51163093e-04  1.10220918e-02 -8.54755938e-02 -2.68255756e-03\n",
      "  1.83174424e-02  1.91116314e-02 -4.73488262e-03 -8.08255840e-03\n",
      "  1.37906978e-02 -7.76046468e-03 -2.82767452e-02 -2.99069774e-03\n",
      "  1.06569799e-02 -5.99999772e-03  1.11883730e-02  4.28720983e-03\n",
      " -3.12255807e-02 -8.07186142e-02  8.59302282e-03 -8.11744668e-03\n",
      " -5.36279054e-03  1.87046509e-02 -1.10972092e-01 -3.07988375e-02\n",
      "  9.47441999e-03 -1.03662787e-02  1.16337193e-02  3.22093032e-02\n",
      " -2.69790720e-02  2.25430205e-02 -1.49802361e-02 -1.05290683e-02\n",
      " -4.36534919e-02  6.34883530e-04 -2.83197612e-02 -1.37674408e-02\n",
      " -1.50220934e-02  1.30851150e-01 -1.22430259e-02  2.38767453e-02]\n"
     ]
    }
   ],
   "source": [
    "v = vectorized_training['George_Washington']['vector']\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the vectorized_training into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDict(d, percent):\n",
    "    split_idx = int(len(d) * percent)\n",
    "    d1 = dict(list(d.items())[: split_idx])\n",
    "    d2 = dict(list(d.items())[split_idx:])                \n",
    "\n",
    "    return d1, d2\n",
    "\n",
    "vectorized_training_test, vectorized_training_train = splitDict(vectorized_training, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342239"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorized_training_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We encode the data\n",
    "import numpy as np\n",
    "\n",
    "def encode_data(vectorized_data):\n",
    "    X = np.array([vectorized_data[article]['vector'] for article in vectorized_data])\n",
    "    y = np.array([[(1 if occupation in vectorized_data[article]['occupations'] else 0)\n",
    "                        for occupation in occupations ] for article in vectorized_data])\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = encode_data(vectorized_training_train)\n",
    "X_test, y_test = encode_data(vectorized_training_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342239, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(342239, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using keras, define a sequential neural network with two layers. Use categorical_crossentropy as a loss function and softmax as the activation function of the output layer\n",
    "\n",
    "You can look into the documentation here: https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=300))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 308015 samples, validate on 34224 samples\n",
      "Epoch 1/50\n",
      "308015/308015 [==============================] - 3s 10us/step - loss: 3.5608 - acc: 0.4881 - val_loss: 2.0247 - val_acc: 0.6362\n",
      "Epoch 2/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 2.3868 - acc: 0.6581 - val_loss: 1.7224 - val_acc: 0.6907\n",
      "Epoch 3/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 2.1847 - acc: 0.6880 - val_loss: 1.6056 - val_acc: 0.7125\n",
      "Epoch 4/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 2.0853 - acc: 0.7033 - val_loss: 1.5498 - val_acc: 0.7234\n",
      "Epoch 5/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 2.0255 - acc: 0.7115 - val_loss: 1.5037 - val_acc: 0.7321\n",
      "Epoch 6/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9833 - acc: 0.7176 - val_loss: 1.4793 - val_acc: 0.7359\n",
      "Epoch 7/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9517 - acc: 0.7213 - val_loss: 1.4538 - val_acc: 0.7409\n",
      "Epoch 8/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9250 - acc: 0.7251 - val_loss: 1.4335 - val_acc: 0.7466\n",
      "Epoch 9/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.9036 - acc: 0.7273 - val_loss: 1.4188 - val_acc: 0.7452\n",
      "Epoch 10/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8846 - acc: 0.7293 - val_loss: 1.4096 - val_acc: 0.7491\n",
      "Epoch 11/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8676 - acc: 0.7324 - val_loss: 1.3920 - val_acc: 0.7537\n",
      "Epoch 12/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8522 - acc: 0.7333 - val_loss: 1.3919 - val_acc: 0.7550\n",
      "Epoch 13/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8387 - acc: 0.7349 - val_loss: 1.3776 - val_acc: 0.7560\n",
      "Epoch 14/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8256 - acc: 0.7372 - val_loss: 1.3729 - val_acc: 0.7587\n",
      "Epoch 15/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8138 - acc: 0.7383 - val_loss: 1.3733 - val_acc: 0.7553\n",
      "Epoch 16/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.8025 - acc: 0.7391 - val_loss: 1.3637 - val_acc: 0.7564\n",
      "Epoch 17/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.7916 - acc: 0.7408 - val_loss: 1.3510 - val_acc: 0.7603\n",
      "Epoch 18/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.7818 - acc: 0.7417 - val_loss: 1.3484 - val_acc: 0.7622\n",
      "Epoch 19/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7721 - acc: 0.7434 - val_loss: 1.3472 - val_acc: 0.7599\n",
      "Epoch 20/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.7634 - acc: 0.7436 - val_loss: 1.3448 - val_acc: 0.7615\n",
      "Epoch 21/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7554 - acc: 0.7450 - val_loss: 1.3347 - val_acc: 0.7649\n",
      "Epoch 22/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7462 - acc: 0.7463 - val_loss: 1.3367 - val_acc: 0.7639\n",
      "Epoch 23/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7388 - acc: 0.7467 - val_loss: 1.3338 - val_acc: 0.7641\n",
      "Epoch 24/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7308 - acc: 0.7481 - val_loss: 1.3379 - val_acc: 0.7646\n",
      "Epoch 25/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7240 - acc: 0.7486 - val_loss: 1.3341 - val_acc: 0.7644\n",
      "Epoch 26/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7173 - acc: 0.7494 - val_loss: 1.3279 - val_acc: 0.7634\n",
      "Epoch 27/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7097 - acc: 0.7500 - val_loss: 1.3268 - val_acc: 0.7610\n",
      "Epoch 28/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.7030 - acc: 0.7510 - val_loss: 1.3203 - val_acc: 0.7664\n",
      "Epoch 29/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6968 - acc: 0.7518 - val_loss: 1.3266 - val_acc: 0.7640\n",
      "Epoch 30/50\n",
      "308015/308015 [==============================] - 1s 5us/step - loss: 1.6907 - acc: 0.7525 - val_loss: 1.3202 - val_acc: 0.7654\n",
      "Epoch 31/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6837 - acc: 0.7533 - val_loss: 1.3224 - val_acc: 0.7615\n",
      "Epoch 32/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6777 - acc: 0.7537 - val_loss: 1.3208 - val_acc: 0.7650\n",
      "Epoch 33/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6719 - acc: 0.7541 - val_loss: 1.3257 - val_acc: 0.7629\n",
      "Epoch 34/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6654 - acc: 0.7554 - val_loss: 1.3239 - val_acc: 0.7624\n",
      "Epoch 35/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6594 - acc: 0.7557 - val_loss: 1.3201 - val_acc: 0.7618\n",
      "Epoch 36/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6540 - acc: 0.7566 - val_loss: 1.3231 - val_acc: 0.7631\n",
      "Epoch 37/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6487 - acc: 0.7568 - val_loss: 1.3197 - val_acc: 0.7663\n",
      "Epoch 38/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6427 - acc: 0.7581 - val_loss: 1.3195 - val_acc: 0.7684\n",
      "Epoch 39/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6375 - acc: 0.7579 - val_loss: 1.3150 - val_acc: 0.7657\n",
      "Epoch 40/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6323 - acc: 0.7581 - val_loss: 1.3244 - val_acc: 0.7619\n",
      "Epoch 41/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6270 - acc: 0.7595 - val_loss: 1.3234 - val_acc: 0.7617\n",
      "Epoch 42/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6214 - acc: 0.7601 - val_loss: 1.3270 - val_acc: 0.7601\n",
      "Epoch 43/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6162 - acc: 0.7604 - val_loss: 1.3214 - val_acc: 0.7638\n",
      "Epoch 44/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6115 - acc: 0.7606 - val_loss: 1.3241 - val_acc: 0.7622\n",
      "Epoch 45/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6061 - acc: 0.7616 - val_loss: 1.3275 - val_acc: 0.7599\n",
      "Epoch 46/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.6012 - acc: 0.7622 - val_loss: 1.3222 - val_acc: 0.7651\n",
      "Epoch 47/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5964 - acc: 0.7628 - val_loss: 1.3247 - val_acc: 0.7631\n",
      "Epoch 48/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5910 - acc: 0.7632 - val_loss: 1.3250 - val_acc: 0.7668\n",
      "Epoch 49/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5868 - acc: 0.7636 - val_loss: 1.3247 - val_acc: 0.7598\n",
      "Epoch 50/50\n",
      "308015/308015 [==============================] - 1s 4us/step - loss: 1.5814 - acc: 0.7645 - val_loss: 1.3295 - val_acc: 0.7646\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=1024, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Complete the function predict: output the list of occupations where the corresponding neuron on the output layer of our model has a value > 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Q177220', 'Q639669', 'Q33999'}\n"
     ]
    }
   ],
   "source": [
    "def predict_nn(model, article_name, vectorized_dataset):\n",
    "    input_vector = vectorized_dataset[article_name]['vector'].reshape((1, 300))\n",
    "    scores = model.predict(input_vector).reshape(100)\n",
    "    predictions = np.where(scores > 0.1)[0]\n",
    "#     print(scores[predictions])\n",
    "    return set(np.array(occupations)[predictions])\n",
    "\n",
    "print(predict_nn(model, 'Elvis_Presley', vectorized_training))\n",
    "# should be {'Q177220'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nn(vectorized_training, model):\n",
    "    nexample = 0\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for article_name in vectorized_training:\n",
    "        prediction = predict_nn(model, article_name, vectorized_training)\n",
    "        p = frozenset(prediction)\n",
    "        g = frozenset(vectorized_training[article_name]['occupations'])\n",
    "        accuracy += 1.*len(p & g) / len(p | g)\n",
    "        nexample += 1\n",
    "    return accuracy / nexample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7048576643356244\n",
      "0.6662116943899452\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_nn(vectorized_training_train, model))\n",
    "print(evaluate_nn(vectorized_training_test, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Your approach - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, LSTM, GRU, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dataset into summaries, titles and occupations\n",
    "def parse(dataset):\n",
    "    titles = []\n",
    "    summaries = []\n",
    "    occs = []\n",
    "    for example in dataset:\n",
    "        titles.append(example['title'])\n",
    "        summaries.append(example['summary'])        \n",
    "        if 'occupations' in example:\n",
    "            occs.append(example['occupations'])\n",
    "    return titles, summaries, occs\n",
    "    \n",
    "titles_train, summaries_train, occs_train = parse(training_set)\n",
    "\n",
    "s = int(len(titles_train) * 0.8)\n",
    "titles_train_train, summaries_train_train, occs_train_train = titles_train[:s], summaries_train[:s], occs_train[:s]\n",
    "titles_train_test, summaries_train_test, occs_train_test = titles_train[s:], summaries_train[s:], occs_train[s:]\n",
    "\n",
    "titles_test, summaries_test, occs_test = parse(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 370295 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(titles_train_train)\n",
    "maxlen = 200\n",
    "training_samples = int(n_samples * 0.85)\n",
    "validation_samples = n_samples - training_samples\n",
    "max_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(summaries_train_train)\n",
    "\n",
    "# convert text to sequences\n",
    "sequences =  tokenizer.texts_to_sequences(summaries_train_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(summaries_train_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found', len(word_index), 'unique tokens.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_occs_to_labels(occupations, occs_train):\n",
    "    labels = []\n",
    "    for i in range(len(occs_train)):\n",
    "        label = []\n",
    "        for occ in occupations:\n",
    "            if occ in occs_train[i]:\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "        labels.append(label)\n",
    "    return np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (342333, 500)\n",
      "Shape of label tensor: (342333, 100)\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "data_test = pad_sequences(sequences_test, maxlen=maxlen)\n",
    "labels = convert_occs_to_labels(occupations, occs_train_train)\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "# shuffle the data\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# split into training and testing set\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = 'glove.6B'\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Found', len(embeddings_index), 'word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding matrix to load into embedding layer\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_words:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 500, 128)          87936     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 1,167,332\n",
      "Trainable params: 1,167,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(GRU(128, \n",
    "              dropout=0.2,\n",
    "              recurrent_dropout=0.2,\n",
    "              return_sequences=True))\n",
    "model.add(GRU(64,\n",
    "              dropout=0.2,\n",
    "              recurrent_dropout=0.2,\n",
    "             ))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Glove embedding in the model\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "# model.layers[0].trainable = False # we will not update this layer during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 290983 samples, validate on 51350 samples\n",
      "Epoch 1/20\n",
      "  6144/290983 [..............................] - ETA: 8:06 - loss: 6.0460 - acc: 0.1274"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-143385385460>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    "    batch_size=1024,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95279896]\n",
      "{'Q14089670'}\n"
     ]
    }
   ],
   "source": [
    "def predict_nn_2(model, input_vector, print_score = False):\n",
    "    \n",
    "    scores = model.predict(input_vector).reshape(100)\n",
    "    predictions = np.where(scores > 0.1)[0]\n",
    "    if print_score:\n",
    "         print(scores[predictions])\n",
    "    return set(np.array(occupations)[predictions])\n",
    "\n",
    "title = 'Elvis_Presley'\n",
    "idx = titles_train.index(title)\n",
    "input_vector = data[idx].reshape(1, maxlen)\n",
    "\n",
    "print(predict_nn_2(model, input_vector, print_score=True))\n",
    "# should be {'Q177220'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85584"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0  :  1.168442699570013e-05\n",
      "0.11684426995700131  :  0.0007933725930080399\n",
      "0.23368853991400262  :  0.0016636676637377733\n",
      "0.35053280987100394  :  0.002492775129307664\n",
      "0.46737707982800525  :  0.0033444863971013776\n",
      "0.5842213497850065  :  0.0041886862475407054\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-38cc38ecc58c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(evaluate_nn_2(titles_train, summaries_train, occs_train, model))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_nn_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccs_train_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-38cc38ecc58c>\u001b[0m in \u001b[0;36mevaluate_nn_2\u001b[0;34m(titles, input_vectors, occs, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minput_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_nn_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d73f81bb2c5b>\u001b[0m in \u001b[0;36mpredict_nn_2\u001b[0;34m(model, input_vector, print_score)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_nn_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprint_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_nn_2(titles, input_vectors, occs, model):\n",
    "    nexample = len(titles)\n",
    "    accuracy = 0.\n",
    "    prediction = None\n",
    "    for i in range(len(titles)):        \n",
    "        input_vector = input_vectors[i].reshape(1, -1)\n",
    "        prediction = predict_nn_2(model, input_vector)\n",
    "        p = frozenset(prediction)\n",
    "        g = frozenset(occs[i])\n",
    "        accuracy += 1. / nexample * len(p & g) / len(p | g)\n",
    "        if i % 100 == 0:\n",
    "            print(i * 100 / nexample, \" : \", accuracy)\n",
    "    return accuracy \n",
    "\n",
    "# print(evaluate_nn_2(titles_train, summaries_train, occs_train, model))\n",
    "print(evaluate_nn_2(titles_train_test, data_test, occs_train_test, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IMPORTANT*** Output format of requested file 'results.json.gz': each line must be a json string representing a dictionnary:\n",
    "> ```{ 'title': THE_ARTICLE_NAME, 'prediction': [THE_LIST_OF_OCCUPATIONS]}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example if testset_solutions is a dictionnary: article_name (key) -> prediction_list (value) use this function:\n",
    "def export(testset_solutions):\n",
    "    with gzip.open('results.json.gz', 'wt') as output:\n",
    "        for article in testset_solutions:\n",
    "            output.write(json.dumps({'title':article, 'prediction':testset_solutions[article]}) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
